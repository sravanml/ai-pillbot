{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhusmart/Uplimit_Langchain_Course/blob/main/Week1/Langchain_Week1_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's build \"PillPal\" - a bot and website that allows users to ask questions based on the Patient Information Leaflet (PIL) or drug guide that comes with any medication."
      ],
      "metadata": {
        "id": "BmgRqB0z3JLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Package Information Leaflet](https://i.ibb.co/ZSdGyjV/ima-image-36904.jpg)"
      ],
      "metadata": {
        "id": "zcmYA3M8aGp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm sure you have all come across the thin piece of folded paper that is part of every drug prescription box. Usually the text is in very small print and typically provides information about dosages, side effects, storage instructions and much more. They are hard to read and understand and requires some effort to get answers to common questions a patient might have. What if we could create a product that answers these questions and actually makes the medical information more accessible and easier to understand - enter PillPal!"
      ],
      "metadata": {
        "id": "oZ-FEcb8SjNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the process of building PillPal, we will go through the following stages and on the way learn more about LLM Apps and their typical life-cycle.\n",
        "\n",
        "1. BUILD the app: this is where we first test the idea, try multiple options for various parts of the pipeline till we are satisfied to a reasonable extent that the product works.\n",
        "2. DEPLOY & MONITOR the app: this is where we want to make the app available to our first users, monitor it's behaviour and discover edge cases.\n",
        "3. EVALUATE & IMPROVE the app: this is the final and ongoing stage where we will build an evaluation suite that constantly checks whether our app is working as expected and perform experiments."
      ],
      "metadata": {
        "id": "0fEvG823VR9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use Langchain to develop the app, deploy it as a Telegram bot/ Website and use Langsmith to monitor, evaluate and improve the product. Please consider PillPal as the chosen example/ case study to illustrate the process but feel free to adapt this project ot build any app of your choice!\n",
        "\n",
        "# # 👨‍🎓 Project\n",
        "\n",
        "In the project walkthrough session we will go through the various steps of the project with an example of one of the drugs. The learner project is to implement the same steps for a different drug OR any other PDF of your choice. Concretely, here are steps that you need to do:\n",
        "\n",
        "1. Identify a PDF that you would like to ask questions about. Suggestion: choose another drug or medication that you are familiar with.\n",
        "2. Upload and use that PDF as you go through this notebook.\n",
        "3. Make use of the sections and flow as a guide but you are expected to update and write code to complete the RAG project for your PDF.\n",
        "4. Feel free to adapt any sections to add more functionality or adapt for your use case/ PDF."
      ],
      "metadata": {
        "id": "I2S69-R7aK0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Necessary libraries and setup"
      ],
      "metadata": {
        "id": "ruybS1MUZ3--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries to get it out of the way\n",
        "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma faiss-gpu pymupdf grandalf gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbQIsr6r6kOq",
        "outputId": "a708cf16-2dea-4033-fcc9-fd4be88a7b3c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m882.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.0/420.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Building the PillPal bot"
      ],
      "metadata": {
        "id": "XS1dSf8E6ZUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The patient information leaflets/ drug booklets are typically available in the form of PDFs from the drug manufacturers website or from a central repository like in the [UK](https://www.medicines.org.uk/) or the [US](https://dailymed.nlm.nih.gov/). While you should be able to find them relatively easily through an Internet Search, we also include the medical booklet PDFs for two drugs with this code repository to use in the project."
      ],
      "metadata": {
        "id": "0It6mAFmW4Qj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the best aspects of using Langchain is that it provides a lot of in-built integrations for most common development tasks while building LLM apps. We will make use of several of them during this project, starting with the PDF loader which we will use to read in the medical booklet PDF file. For this example, we have chosen the PIL for Ozempic - a new drug that decreses the risk of heart disease in overweight patients but has been in the news recently for also being a weight loss solution."
      ],
      "metadata": {
        "id": "DXAlB_g8ZGM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Step 1.1:\n",
        "\n",
        "In the following section, you have to load in your PDF using any of the document loaders available from the Langchain Community package. For example: you could use the `PyMuPDFLoader` for managing PDFs.\n",
        "\n",
        "Your code should do the following:\n",
        "- Load the PDF\n",
        "- Identify the number of pages\n",
        "- Print one of the pages with the associated metadata"
      ],
      "metadata": {
        "id": "S505i8I5MbI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader(\"/content/pil.9748.pdf\")\n",
        "data = loader.load()\n",
        "\n",
        "print(\"The PDF contians\",len(data),\" pages\")"
      ],
      "metadata": {
        "id": "n2nJ6tyN7758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f102c690-d5ff-453a-b210-02162e65759e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The PDF contians 11  pages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The additional metadata like page number and title is relevant to our product because when we answer questions: we can also point users to specific sections of the original document which they can refer to for more clarity."
      ],
      "metadata": {
        "id": "H1ksk-czaxN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next step is to index this entire document which we do with the help of OpenAI embeddings. However, before we do that we need to split document into chunks so that at the time of retrieval we are identifying the correct parts of the document. We use one of the in-built Langchain components that allows us to split based on characters based on our specifications.\n",
        "\n",
        "We have chosen to split the entire document into chunks of length 2000 characters and also ensure an overlap of 200 characters. This makes sure that we are not loosing any information when splitting up the document. As we will see later, this is one of the parameters that we can control and could have an influence on the performance of our product."
      ],
      "metadata": {
        "id": "8eI1CZqcbF7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Step 1.2:\n",
        "\n",
        "In the following section, you have to decide the best chunking strategy for your PDF and use case. For instance, you could make use of the `RecursiveCharacterTextSplitter` to work with text documents. It's important to also decide what are reasonable values for `chunk_size` and `chunk_overlap`. In the project walkthrough we provide some suggested values."
      ],
      "metadata": {
        "id": "PbkgyfD9NryJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "4xMZXPdM9fae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are optimising for retrieval - i.e. how fine-grained is the context that we can retrieve so that we can answer the question that our user is asking. In this case, it might be better to have a smaller chunk because you are then narrowing down on the perfect part of the text where this information is present."
      ],
      "metadata": {
        "id": "7tqcP7ljBQsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from google.colab import userdata\n",
        "\n",
        "## Define the embedding model below by using the `text-embedding-3-small` model\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small', openai_api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "UBVkp6TbaZDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A huge advantage of using Langchain is that it provides integrations with several types of vector databases like Chroma, Pinecone and more. In this project, we make use of the FAISS library from Facebook/Meta as a simple choice. In the following section, we combine the steps of generating the embedding value for each document chunk and then also storing it into the FAISS vector database."
      ],
      "metadata": {
        "id": "IDaUK7NbE8J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS.from_documents(documents=splits, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "NDV_HnMFFJfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have our documents indexed and we can directly start retrieving documents based on a similarity search with a target query."
      ],
      "metadata": {
        "id": "_nI7cwlNdiBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_result = vector_store.similarity_search_with_relevance_scores(query=\"What is the recommended dosage?\", k=4)\n",
        "search_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1_wRhCQJBLJ",
        "outputId": "f9b76616-5ff0-4647-fd5e-8f35b0672c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(metadata={'source': '/content/pil.9748.pdf', 'file_path': '/content/pil.9748.pdf', 'page': 1, 'total_pages': 11, 'format': 'PDF 1.6', 'title': 'Ozempic, INN-semaglutide', 'author': 'CHMP', 'subject': 'EPAR', 'keywords': 'Ozempic, INN-semaglutide', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20241001105818+01'00'\", 'modDate': \"D:20241001105824+01'00'\", 'trapped': ''}, page_content='This medicine is not recommended in children and adolescents aged under 18 years as the safety and \\nefficacy in this age group have not yet been established. \\n \\nOther medicines and Ozempic® \\nTell your doctor, pharmacist or nurse if you are taking, have recently taken or might take any other \\nmedicines, including herbal medicines or other medicines you bought without a prescription. \\n \\nIn particular, tell your doctor, pharmacist or nurse if you are using medicines containing any of the \\nfollowing: \\n• \\nWarfarin or other similar medicines taken by mouth to reduce blood clotting (oral anti-\\ncoagulants). You may need frequent blood tests to check how quickly your blood clots. \\n• \\nIf you are using insulin, your doctor will tell you how to reduce the dose of insulin and will \\nrecommend you to monitor your blood sugar more frequently, in order to avoid hyperglycaemia \\n(high blood sugar) and diabetic ketoacidosis (a complication of diabetes that occurs when the \\nbody is unable to break down glucose because there is not enough insulin). \\n \\nPregnancy and breast-feeding  \\nIf you are pregnant or breast-feeding, think you might be pregnant, or are planning to have a baby, ask \\nyour doctor for advice before taking this medicine. \\n \\nThis medicine should not be used during pregnancy, as it is not known if it affects an unborn baby. \\nTherefore, use of contraception is recommended while using this medicine. If you wish to become \\npregnant, discuss how to change your treatment with your doctor as you should stop using this'),\n",
              "  0.11403556501843881),\n",
              " (Document(metadata={'source': '/content/pil.9748.pdf', 'file_path': '/content/pil.9748.pdf', 'page': 2, 'total_pages': 11, 'format': 'PDF 1.6', 'title': 'Ozempic, INN-semaglutide', 'author': 'CHMP', 'subject': 'EPAR', 'keywords': 'Ozempic, INN-semaglutide', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20241001105818+01'00'\", 'modDate': \"D:20241001105824+01'00'\", 'trapped': ''}, page_content='medicine at least 2 months in advance. If you become pregnant while using this medicine, talk to your \\ndoctor right away, as your treatment will need to be changed. \\n \\nDo not use this medicine if you are breast-feeding, as it is unknown if it passes into breast milk. \\n \\nDriving and using machines  \\nOzempic® is unlikely to affect your ability to drive and use machines. If you use this medicine in \\ncombination with a sulfonylurea or insulin, low blood sugar (hypoglycaemia) may occur which may \\nreduce your ability to concentrate. Do not drive or use machines if you get any signs of low blood \\nsugar. See section 2, ‘Warnings and precautions’ for information on increased risk of low blood sugar \\nand section 4 for the warning signs of low blood sugar. Talk to your doctor for further information.  \\n \\nSodium content \\nThis medicine contains less than 1 mmol sodium (23 mg) per dose, that is to say essentially ‘sodium-\\nfree’.  \\n \\n \\n3. \\nHow to use Ozempic® \\n \\nAlways use this medicine exactly as your doctor has told you. Check with your doctor, pharmacist or \\nnurse if you are not sure. \\n \\nHow much to use \\n• \\nThe starting dose is 0.25 mg once a week for four weeks. \\n• \\nAfter four weeks your doctor will increase your dose to 0.5 mg once a week. \\n• \\nYour doctor may increase your dose to 1 mg once a week if your blood sugar is not controlled \\nwell enough with a dose of 0.5 mg once a week. \\n• \\nYour doctor may increase your dose to 2 mg once a week if your blood sugar is not controlled \\nwell enough with a dose of 1 mg once a week. \\n \\nDo not change your dose unless your doctor has told you to. \\n \\nHow Ozempic® is given \\nOzempic® is given as an injection under the skin (subcutaneous injection). Do not inject it into a vein \\nor muscle. \\n• \\nThe best places to give the injection are the front of your thighs, the front of your waist \\n(abdomen), or your upper arm. \\n• \\nBefore you use the pen for the first time, your doctor or nurse will show you how to use it.'),\n",
              "  0.09984337242566843),\n",
              " (Document(metadata={'source': '/content/pil.9748.pdf', 'file_path': '/content/pil.9748.pdf', 'page': 8, 'total_pages': 11, 'format': 'PDF 1.6', 'title': 'Ozempic, INN-semaglutide', 'author': 'CHMP', 'subject': 'EPAR', 'keywords': 'Ozempic, INN-semaglutide', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20241001105818+01'00'\", 'modDate': \"D:20241001105824+01'00'\", 'trapped': ''}, page_content='If no drop appears, repeat step 2 ‘Check the flow with each new pen’ up to 6 times. If there is still no drop, \\nchange the needle and repeat step 2 ‘Check the flow with each new pen’ once more. \\nDispose of the pen and use a new one if a drop of solution still does not appear. \\n \\nAlways make sure that a drop appears at the needle tip before you use a new pen for the first time. \\nThis makes sure that the solution flows. \\n \\nIf no drop appears, you will not inject any medicine even though the dose counter may move. This \\nmay indicate a blocked or damaged needle. \\n \\nIf you do not check the flow before your first injection with each new pen, you may not get the \\nprescribed dose and the intended effect of Ozempic®. \\n3. Select your dose \\n• \\nTurn the dose selector to select 0.25 mg. \\n \\nKeep turning until the dose counter stops and shows \\n0.25 mg. \\n \\n \\n A \\n0.25 mg \\nselected \\n \\nOnly the dose counter and dose pointer will show that 0.25 mg has been selected. \\nYou can only select 0.25 mg per dose. \\nThe dose selector clicks differently when turned forwards, backwards or past 0.25 mg. Do not count the pen \\nclicks. \\n \\nAlways use the dose counter and the dose pointer to see that 0.25 mg has been selected before \\ninjecting this medicine.  \\n \\nDo not count the pen clicks.  \\n \\n0.25 mg must line up precisely with the dose pointer to ensure that you get a correct dose. \\n4. Inject your dose \\n• \\nInsert the needle into your skin as your doctor or nurse \\nhas shown you. \\n• \\nMake sure you can see the dose counter. Do not cover \\nit with your fingers. This could interrupt the injection. \\n A \\n \\n• \\nPress and hold down the dose button. Watch as the \\ndose counter returns to ‘0’. The ‘0’ must line up with \\nthe dose pointer. You may then hear or feel a click. \\n \\n• \\nContinue pressing the dose button while keeping the \\nneedle in your skin. \\n B \\n \\n• \\nCount slowly to 6, while keeping the dose button \\npressed. \\n• \\nIf the needle is removed earlier, you may see a stream of'),\n",
              "  0.08552617228021475),\n",
              " (Document(metadata={'source': '/content/pil.9748.pdf', 'file_path': '/content/pil.9748.pdf', 'page': 3, 'total_pages': 11, 'format': 'PDF 1.6', 'title': 'Ozempic, INN-semaglutide', 'author': 'CHMP', 'subject': 'EPAR', 'keywords': 'Ozempic, INN-semaglutide', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20241001105818+01'00'\", 'modDate': \"D:20241001105824+01'00'\", 'trapped': ''}, page_content='If you forget to use Ozempic®  \\nIf you forgot to inject a dose and: \\n• \\nit is 5 days or less since you should have used Ozempic®, use it as soon as you remember. Then \\ninject your next dose as usual on your scheduled day. \\n• \\nit is more than 5 days since you should have used Ozempic®, skip the missed dose. Then inject \\nyour next dose as usual on your scheduled day. \\nDo not use a double dose to make up for a forgotten dose. \\n \\nIf you stop using Ozempic®  \\nDo not stop using this medicine without talking to your doctor. If you stop using it, your blood sugar \\nlevels may increase. \\n \\nIf you have any further questions on the use of this medicine, ask your doctor, pharmacist or nurse. \\n \\n \\n4. \\nPossible side effects \\n \\nLike all medicines, this medicine can cause side effects, although not everybody gets them.  \\n \\nSerious side effects \\n \\nCommon (may affect up to 1 in 10 people) \\n• \\ncomplications of diabetic eye disease (retinopathy) – you should tell your doctor if you get eye \\nproblems, such as changes in vision, during treatment with this medicine. \\n \\nUncommon (may affect up to 1 in 100 people) \\n• \\nInflamed pancreas (acute pancreatitis) which could cause severe pain in the stomach and back \\nwhich does not go away. You should see a doctor immediately if you experience such \\nsymptoms. \\n \\nRare (may affect up to 1 in 1 000 people) \\n• \\nsevere allergic reactions (anaphylactic reactions, angioedema). You must get immediate medical \\nhelp and inform your doctor straight away if you get symptoms such as breathing problems, \\nswelling of face, lips, tongue and/or throat with difficulty swallowing and a fast heartbeat. \\n \\nNot known (frequency cannot be estimated from the available data)  \\n• Bowel obstruction. A severe form of constipation with additional symptoms such as stomach ache, \\nbloating, vomiting etc.  \\n \\nOther side effects  \\n \\nVery common (may affect more than 1 in 10 people)  \\n• \\nfeeling sick (nausea) – this usually goes away over time \\n•'),\n",
              "  0.080261693726416)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we have chosen to use cosine similarity as our distance metric and the similarity values are also shown along with the retrieved results. You will notice that not many of the retrieved chunks actually contain the text \"Weight Loss\" - and this is because we are not doing a word-based search but rather semantic search. This is what vector databases allow us to do. However, it is also possible that at times we want to match exact query terms and then we will follow a hybrid search approach. This is again one of the levers that we have to expriment with to determine what is necessary for our product. So it's important that you are able to determine what is the best method for you to choose - depends a lot on your use-case."
      ],
      "metadata": {
        "id": "SxPewWEYLG1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the QnA RAG chain"
      ],
      "metadata": {
        "id": "H_MbjNwSaEOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's move on to complete our product by integrating with the LLM. Here again, we rely heavily on the building blocks that Langchain already provides us to put together the entire chain.\n",
        "\n",
        "The chain consists of multiple parts - a Retriever, followed by a Prompt Template where the retrieved documents are added and then the call to the LLM. The response from the LLM is what we finally show as output to the user. There are multiple steps in creating a RAG application. We break it down to make it easier to understand and follow."
      ],
      "metadata": {
        "id": "i7eiBrgeetbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Step 1.3:\n",
        "Creating the Prompt Template. In the section below, please create the PromptTemplate that will be used for your RAG application. The `ChatPromptTemplate` has become the standardized way to use chat-based LLMs and consists of a `SystemMessage`, followed by the `HumanMessage` with the response from the LLM stored in the `AIMessage`. We have provided the necessary imports in the below cell and request you to create the variable `qna_prompt_template` that will be used in the application."
      ],
      "metadata": {
        "id": "HlqW4TbcOfBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import SystemMessagePromptTemplate\n",
        "from langchain.prompts import HumanMessagePromptTemplate\n",
        "\n",
        "## Your code here\n",
        "qna_prompt = \"\"\"\n",
        "You are an expert medical assistant who is able to read information from medicine leaflets\n",
        "and use that to answer any questions that are asked of you.\n",
        "You explain things simply and in an easy to understand manner.\n",
        "If you still can't figure out the answer, just say that you're unable to answer.\n",
        "\n",
        "You are provided with the Question and Context below to help you answer.\n",
        "\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "qna_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(\"You are a helpful AI assistant\"),\n",
        "        HumanMessagePromptTemplate.from_template(qna_prompt),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "5cv_Fi0IPfn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the PromptTemplate, the next step is to define the LLM Model that you would like to run with. We provide the OpenAI API models as the default option and in this case have selected `gpt-3.5-turbo`. Feel free to choose a different model, for e.g. the newly launched `gpt-4o-mini` if you would like to change it. We also set the `temperature` value to 0 as we do not want the model to be creative but rather answer based on the retrieved context from the PDF."
      ],
      "metadata": {
        "id": "iumOVFV4Pk_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
        "                 temperature=0,\n",
        "                 openai_api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "9-wDIb1gQI7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to initilize the retriever part of our application that will fetch the relevant documents from the PDF. Recall that we have already created the embeddings for our document chunks and stored it using the FAISS vectorstore. In this step, we only specify that vectorestore to be our retriever."
      ],
      "metadata": {
        "id": "nDlnYaodQPeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "hz_SleAiQrTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One additional step that we need to also consider is that when the documents are retrieved from the FAISS vectorstore, they are in the form of a list of documents. These document objects contain a lot more information other than the content like Metadata. Assuming we are performing a simple retrieval, the context that we want to pass to the LLM is only the text content. Therefore we write an additional function that combines only the retrieved text content that can be used to pass in the context of our PromptTemplate.\n",
        "\n",
        "Please note that you could also choose to filter the retrieved documents based on the Metadata. For instance, if you only want to see results from Page 5 and beyond of the PDF - then you can also adapt this function to reflect that."
      ],
      "metadata": {
        "id": "zEtojMFZQyjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "b64wwSooQv2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final stage is to put together the various elements that we have defined above to create our pipeline. The key aspect to note here is that the input question is used twice during the process -> at the first instance to retrieve a list of the relevant context and the second instance when it is passed to the LLM as the question that needs to be answered.\n",
        "\n",
        "So we make use of the `itemgetter` to retrieve the content of the question and pass to the retriever to get the relevant context. On the other hand, we make use of the `RunnablePassthrough` class to directly pass the input question to the subsequent operation. At the end we also add the `StrOuputParser` to get the actual text message of the response rather than the whole AIMessage."
      ],
      "metadata": {
        "id": "0VVUVqJARaYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"input\") | retriever | format_docs,\n",
        "     \"question\": RunnablePassthrough()}\n",
        "    | qna_prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "VI7UOE70LleJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please check that your entire chain works by providing your questions and invoking the RAG chain."
      ],
      "metadata": {
        "id": "t5YW6DF-Sog3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \" is it for adults\"\n",
        "rag_chain.invoke({\"input\": question})"
      ],
      "metadata": {
        "id": "ftZIkyQISoAt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cefc3a5a-529b-4722-f74b-3f83420b1ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This medicine, Ozempic®, is not recommended for use in children and adolescents under 18 years old. It is specifically indicated for adults aged 18 years and older with type 2 diabetes. It is important to follow the guidance of your doctor, pharmacist, or nurse regarding the appropriate use of this medication. If you have any further questions or concerns, it is recommended to consult with your healthcare provider for personalized advice.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Step 1.4:\n",
        "If you run into errors as you develop, visualizing the chain is an easy way to discover any issues. This visualization helps us understand the entire flow of operations within our application. By graphically representing the connections and interactions between different components we can see how the data flows and in which shape from one path tothe next. It allows for easier debugging and we might be able to pinpoint where modifications might be necessary."
      ],
      "metadata": {
        "id": "PBbDadkAT1zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (rag_chain.get_graph().print_ascii())"
      ],
      "metadata": {
        "id": "l50o8HECL53q",
        "outputId": "0bfd7032-7885-44a6-8a55-c7099ec8f2d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           +---------------------------------+        \n",
            "           | Parallel<context,question>Input |        \n",
            "           +---------------------------------+        \n",
            "                    **              ***               \n",
            "                 ***                   **             \n",
            "               **                        ***          \n",
            "       +--------+                           **        \n",
            "       | Lambda |                            *        \n",
            "       +--------+                            *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "+----------------------+                     *        \n",
            "| VectorStoreRetriever |                     *        \n",
            "+----------------------+                     *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "            *                                *        \n",
            "    +-------------+                   +-------------+ \n",
            "    | format_docs |                   | Passthrough | \n",
            "    +-------------+*                  +-------------+ \n",
            "                    **              **                \n",
            "                      ***        ***                  \n",
            "                         **    **                     \n",
            "          +----------------------------------+        \n",
            "          | Parallel<context,question>Output |        \n",
            "          +----------------------------------+        \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                  +--------------------+              \n",
            "                  | ChatPromptTemplate |              \n",
            "                  +--------------------+              \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                      +------------+                  \n",
            "                      | ChatOpenAI |                  \n",
            "                      +------------+                  \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                   +-----------------+                \n",
            "                   | StrOutputParser |                \n",
            "                   +-----------------+                \n",
            "                            *                         \n",
            "                            *                         \n",
            "                            *                         \n",
            "                +-----------------------+             \n",
            "                | StrOutputParserOutput |             \n",
            "                +-----------------------+             \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hopefully, you have managed to build the skeleton for your product. At first just make sure that everything is working in an end to end fashion. After you have achieved that you can move in the direction of improving the answers from the application. This is when you can start experimenting with different aspects of your pipeline to go in the direction of a better solution.\n",
        "\n",
        "We would recommend adapting the following options:\n",
        "\n",
        "- Chunk size:\n",
        "- Retrieval strategy/ metric:\n",
        "- Choice of LLM:"
      ],
      "metadata": {
        "id": "VwTao9CgfNrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of this stage, you should be able to have a working prototype of your solution that does reasonably well for the use-case you have in mind.\n",
        "\n",
        "We are still relying on a vibe/gut-feel for the product and cannot rely on quantified metrics. But hopefully you can feel reasonably confident to launch an alpha version of your product to a select group of customers."
      ],
      "metadata": {
        "id": "IvhtzIRbfrec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Deploying the PillPal bot"
      ],
      "metadata": {
        "id": "NlvAHj4bPl6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before deploying our product, one of the important steps is to enable tracking and monitoring all the user queries and LLM responses. This is made very easy for us with the help of Langsmith - another part of the Langchain ecosystem.\n",
        "\n",
        "This is one of the cornerstones of our strategy to get towards a more valuable and performing LLM app.\n",
        "\n",
        "Please sign-up on the Langsmith [Website](https://smith.langchain.com/) and you should have access. Next, please navigate to the Settings page from the left side navigation menu and then create your API key there and copy it.\n",
        "\n",
        "<a href=\"https://ibb.co/fN8s3Yp\"><img src=\"https://i.ibb.co/ZgH0Q68/Screenshot-2024-07-26-at-16-12-48.png\" alt=\"Screenshot-2024-07-26-at-16-12-48\" border=\"0\"></a>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "After that, you can return to the main page and click the New Project icon and copy the environment details that you see.\n",
        "\n",
        "<a href=\"https://ibb.co/th2CQhd\"><img src=\"https://i.ibb.co/yRksdR3/Screenshot-2024-07-26-at-16-12-59.png\" alt=\"Screenshot-2024-07-26-at-16-12-59\" border=\"0\"></a>"
      ],
      "metadata": {
        "id": "0X3ZhG3_PqrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ['LANGCHAIN_PROJECT'] = \"pr-drab-infix-3\""
      ],
      "metadata": {
        "id": "WeuJlFzdOnBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can deploy our LLM app in two different ways -\n",
        "\n",
        "1. A website based chatbot experience - this will be done with the help of Gradio and you do not need to leave the Colab notebook environment\n",
        "2. A telegram chatbot that will run on Github Codespaces (or locally) and will need you to leave the Colab environment"
      ],
      "metadata": {
        "id": "-AylFlTLPyp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deployed as website chatbot\n",
        "\n",
        "We can deploy our QnA bot on a dedicated website using Gradio, an easy-to-use library for creating interactive machine learning interfaces. One significant advantage of using Gradio in our project is that it integrates seamlessly within the Colab notebook environment. This means you don't need to leave Colab to see your bot in action; you can run it directly from the notebook. Gradio also provides a dedicated URL that you can share with potential beta testers of the QnA bot to get feedback."
      ],
      "metadata": {
        "id": "4TQ_kDighGgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "def predict(message, history):\n",
        "    return rag_chain.invoke({\"input\":message})\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "DDy0V7_eoEYt",
        "outputId": "a44cc5b7-11e4-4e74-f6da-d8f53d1daa29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:228: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://31e628cadb0f80ac79.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://31e628cadb0f80ac79.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Evaluation of PillPal"
      ],
      "metadata": {
        "id": "Y_4zSQWPQM-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have deployed and made our app live, we need to consistently monitor how it performs. This is also a way for us to understand what questions are being asked by our users and whether the bot is responding correctly or not. For this we will make use of the Langsmith part of the Langchain library."
      ],
      "metadata": {
        "id": "m9wzLbcQptfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the first step, we have to create a validation dataset that we can use for evaluation. There are several ways to go about doing this:\n",
        "\n",
        "1. Launch your app in beta and get some trial users to start interacting with the bot/chat interface and identify common patterns and questions that are being asked. Manually, write your own answers to these questions and perform evaluations using that.\n",
        "2. Come up with a list of 5-10 questions and manually search for the answers of these questions in the PDF and create this as your evaluation dataset -> this is what we are going to do below.  \n",
        "3. You could also make use of another LLM to come up with these questions and answers which is called creating a synthetic dataset. This would work well if you use higher level models like GPT-4 but you need to keep in mind that they have to be relevant to the context of your leaflet."
      ],
      "metadata": {
        "id": "Gvj_e6UYon-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a base evaluation dataset"
      ],
      "metadata": {
        "id": "b-H03qVVaMkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure that our application is functioning correctly and effectively answering questions, we have implemented a basic sanity check. This involves a set of 8-10 questions that I have manually curated and answered after thoroughly reviewing the content of the PDF document. These questions are designed to cover a wide range of topics and complexities within the document, ensuring that they test various aspects of our QnA bot's capabilities. By comparing the answers generated by our bot to these manually prepared responses, we can gauge the accuracy and reliability of our system. This step is crucial as it helps us identify any discrepancies or areas needing improvement before the application is deployed for wider use. Additionally, it provides an initial layer of validation and builds confidence in the application's performance among users and stakeholders."
      ],
      "metadata": {
        "id": "6xTfANXXXd5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Step 3.1:\n",
        "\n",
        "Please create a set of question and correct answer pairs here to use as your evaluation dataset. We have provided the first two questions as examples but feel free to overwrite and add your own."
      ],
      "metadata": {
        "id": "Vv6vi_EAT89n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    (\n",
        "        \"Can it be taken by pregnant women?\",\n",
        "        \"No, it should not be taken by pregnant women before seeking the doctors advice.\",\n",
        "    ),\n",
        "    (\n",
        "        \"Can it be given to children?\",\n",
        "        \"No, it should be taken by children aged less than 6 years old. Children above the age of 6 must follow the prescribed dosage - half a tablet twice daily for children between 6 and 12 years.\",\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "wXFxOClWQPbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have successfully created our dataset, the next step involves registering it with the Langsmith client. This process integrates the dataset into our evaluation framework. By registering the dataset, we effectively add it to the list of datasets available for testing and validating our model. In general, you might create multiple datasets to test various aspects of the QnA bot and might run different types of evaluations on it.\n",
        "\n",
        "In this case, we are running a test for general correctness of the QnA bot - while this does include checks for hallucinations -> we have added examples where the bot should not have an answer and must say so. But there are additional datasets that you might create with separate evaluation metrics to explicitly check for hallucination and fact-checking."
      ],
      "metadata": {
        "id": "x82VVhfGqJ9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()"
      ],
      "metadata": {
        "id": "hGqC94J7qSEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from langsmith import schemas as ls_schemas\n",
        "\n",
        "dataset_name = f\"PillPal QA {str(uuid.uuid4())}\"\n",
        "dataset = client.create_dataset(dataset_name=dataset_name, data_type=ls_schemas.DataType.llm)\n",
        "for q, a in examples:\n",
        "    client.create_example(\n",
        "        inputs={\"input\": q}, outputs={\"output\": a}, dataset_id=dataset.id\n",
        "    )"
      ],
      "metadata": {
        "id": "2EbuuZNMqTRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the above cells are run, you should now be able to see the dataset created in the dataset folder in your Langsmith project.\n",
        "\n",
        "![QA Dataset](https://i.ibb.co/sH5dv86/Xnapper-2024-06-11-20-58-53.png)"
      ],
      "metadata": {
        "id": "EqUUjzJUq_F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the evaluation of our app using this dataset.\n",
        "\n",
        "By executing the code below, we will first be calling our app for each of the questions in our QA dataset. Once the answers have been generated, we need to evaluate it with the golden standard answers that we have written manually. But the big question is always: how can we compare two texts, what metrics shall we use?\n",
        "\n",
        "One of the easier ways to do this is by using another LLM to compare the two responses and tell you whether they match or not. This is also referred to as 'LLM-as-a-judge'. In this case, since we have only 5-10 examples you can easily do this manually but typically your evaluation datasets will contain a lot of examples and this method would not work.\n",
        "\n",
        "We will use the off-the-shelf QA evaluator that Langsmith provides us. Under the hood, it creates a system prompt and desired response automatically for us and we can pick which LLM we would to use as our judge. Typically we make use of a bigger, more powerful LLM to act as the judge for what the smaller, cheaper LLM has generated."
      ],
      "metadata": {
        "id": "kcZrdxNVrci2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.smith import RunEvalConfig\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "eval_config = RunEvalConfig(\n",
        "    evaluators=[\"qa\"],\n",
        "    eval_llm=ChatOpenAI(model_name=\"gpt-4\", openai_api_key=userdata.get('OPENAI_API_KEY'))\n",
        ")"
      ],
      "metadata": {
        "id": "vMe1SzrvrKMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the evaluation on the dataset. You get the links to where you can track the run and at the end the output is also printed here."
      ],
      "metadata": {
        "id": "nd_6YQfQsvgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.run_on_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    llm_or_chain_factory=lambda: rag_chain,\n",
        "    evaluation=eval_config,\n",
        ")"
      ],
      "metadata": {
        "id": "YtKhdYCZsyKz",
        "outputId": "26cf9a11-be40-4332-abb1-279b5812cc3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'stupendous-music-80' at:\n",
            "https://smith.langchain.com/o/65a89521-d351-585d-80e0-b5c278d2180b/datasets/c1126ec2-01d9-4d3b-93d5-34e4c515b5a0/compare?selectedSessions=39f6f667-2b27-4fbb-8d96-d66880ae76cc\n",
            "\n",
            "View all tests for Dataset PillPal QA 6610cee9-070c-43c9-b1db-bede57fe8651 at:\n",
            "https://smith.langchain.com/o/65a89521-d351-585d-80e0-b5c278d2180b/datasets/c1126ec2-01d9-4d3b-93d5-34e4c515b5a0\n",
            "[------------------------------------------------->] 10/10"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'project_name': 'stupendous-music-80',\n",
              " 'results': {'f38cd15c-282e-43cf-8fda-f388aeff83f2': {'input': {'input': 'What should I do if I miss a dose?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('037d4c11-bd78-43c1-ac34-50dfce454165'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 2.173642,\n",
              "   'run_id': 'dee089a2-dffa-4ac7-b719-638e81f7dd0f',\n",
              "   'output': \"If you forget to take Cetirizine Hydrochloride Tablets, do not take a double dose to make up for the missed dose. Instead, take the missed tablet as soon as you remember, but wait at least 24 hours before taking your next tablet. It's important to follow this guidance to avoid any potential risks or side effects associated with taking too much of the medication. If you have any concerns or questions about missed doses or your medication regimen, it's best to consult your doctor or pharmacist for further advice.\",\n",
              "   'reference': {'output': 'Please do not take a double dose to make up for a forgotten dose. If you forget to take a tablet, you should take one as soon as you remember, but wait at least 24 hours before taking your next tablet.'}},\n",
              "  'ef3f59ba-257a-4b9e-a2b7-7a50042ffa1c': {'input': {'input': 'How should this medication be taken?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('b37cbe56-7b51-45ef-a726-f1844c3f51b7'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 3.930642,\n",
              "   'run_id': '6df1e2a3-7891-4990-9419-98ce82995681',\n",
              "   'output': 'To take Cetirizine Hydrochloride Tablets, adults, elderly patients, and children 12 years and over should take 10 mg once daily as one tablet daily. If the tablets make you feel drowsy or dizzy, taking half a tablet twice a day may be better than taking one tablet once a day. For children aged 6 to 12 years, the recommended dose is half a tablet twice daily. Children under 6 years should not take this medication. Patients with moderate renal impairment are recommended to take 5 mg once daily, and those with severe kidney problems should consult their doctor or pharmacist for appropriate dosing adjustments. If you feel that the effect of the medication is too weak or too strong, consult your doctor. Always swallow the tablets with water and do not exceed one tablet per day. If you forget to take a tablet, take one as soon as you remember, but wait at least 24 hours before taking the next dose. If you have any further questions on the use of this medicine, ask your doctor or pharmacist.',\n",
              "   'reference': {'output': 'The tablet should be swallowed with water.'}},\n",
              "  '69d718ac-edd4-46f2-abde-df276b3b1283': {'input': {'input': 'How long can I take the medication?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('dc0bcee7-a59a-4834-ae3d-1189c618df84'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 1.92345,\n",
              "   'run_id': '74dcbfea-0591-4913-8679-21c08a4cf942',\n",
              "   'output': 'The duration of treatment with Cetirizine Hydrochloride Tablets depends on the type, duration, and course of your complaints. It is recommended to ask your doctor or pharmacist for advice regarding how long you can take the medication. It is important to follow their guidance on the duration of treatment to ensure safe and effective use of the medication.',\n",
              "   'reference': {'output': 'The duration of the treatment depends on the type, duration and course of your complaints and you must ask the doctor or pharmacist for advice.'}},\n",
              "  'e1ac3e6b-2857-440b-9260-02598c3ea7cc': {'input': {'input': 'Can I take it if I have Diabetes?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('67eef4c5-1f32-484c-8ef8-a340a4e2f337'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 2.00494,\n",
              "   'run_id': 'c3bf2b0a-82ac-4c1b-b792-e0294d062511',\n",
              "   'output': 'Based on the information provided in the leaflet for Cetirizine Hydrochloride Tablets, it is recommended to consult with a doctor before taking this medicine if you have diabetes. While the leaflet does not specifically mention diabetes as a contraindication, it is always best to seek medical advice before starting any new medication, especially if you have a pre-existing medical condition like diabetes. Your doctor can provide personalized guidance based on your individual health status and medication regimen.',\n",
              "   'reference': {'output': 'I am unable to answer this question based on the information provided.'}},\n",
              "  '79cf404a-20e7-4ade-a798-62845c33cafe': {'input': {'input': 'What are the side effects?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('07b5f94d-0a5b-4630-969b-071c48908d31'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 4.594349,\n",
              "   'run_id': '5a48ce59-702e-435f-8254-a906714be8a2',\n",
              "   'output': \"The possible side effects of Cetirizine Hydrochloride Tablets include:\\n\\nCommon side effects (may affect up to 1 in 10 patients):\\n- Somnolence (sleepiness)\\n- Dizziness, headache\\n- Diarrhoea, nausea, dry mouth\\n- Fatigue\\n- Pharyngitis, cold-like symptoms\\n\\nUncommon side effects (may affect up to 1 in 100 patients):\\n- Feeling agitated\\n- Paresthesia (abnormal feelings of the skin)\\n- Abdominal pain\\n- Pruritus (itchy skin), rash\\n- Asthenia (extreme fatigue), malaise (feeling generally unwell)\\n\\nRare side effects (may affect up to 1 in 1000 patients):\\n- Depression, hallucination (hearing or seeing things), aggression, confusion, sleeplessness\\n- Convulsions\\n- Tachycardia (heart beating too fast)\\n- Liver function abnormal\\n- Urticaria (hives)\\n- Oedema (generalised swelling due to water retention)\\n- Weight increased\\n\\nVery rare side effects (may affect up to 1 in 10,000 patients):\\n- Low levels of blood platelets causing unusual bleeding or bruising\\n- Tics (habit spasm)\\n\\nRemember, if you experience any side effects while taking Cetirizine Hydrochloride Tablets, it's important to talk to your doctor, pharmacist, or nurse.\",\n",
              "   'reference': {'output': 'The most common side effects are Somnolence (sleepiness), Dizziness or headache, diarrhoea, nausea, dry mouth, Fatigue. One may observe Pharyngitis or cold like symptoms of the nose in children. While there are other ways to connect, environment variables tend to be the simplest way to configure your application.'}},\n",
              "  '6447902b-258f-48bb-a855-258686468c91': {'input': {'input': 'Can I take it along with Magnesium supplements?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('6d8551f9-4284-4459-918f-6f67ab8acae7'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 1.421456,\n",
              "   'run_id': '339c1a92-03fe-4e25-bac7-34da5eb6f5d7',\n",
              "   'output': 'Based on the information provided in the leaflet for Cetirizine Hydrochloride Tablets, there is no specific mention of interactions with Magnesium supplements. It is always recommended to consult with your doctor or pharmacist before taking any new medication or supplement to ensure there are no potential interactions or adverse effects. If you have any concerns about taking Cetirizine along with Magnesium supplements, it is best to seek advice from a healthcare professional.',\n",
              "   'reference': {'output': 'I am unable to answer this question based on the information provided.'}},\n",
              "  'a6d2bc93-93f1-4472-9483-ba61cff1c254': {'input': {'input': 'What is the recommended dosage?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('7ac59854-4d3c-4ebc-bb27-b5ec9e6cd26c'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 2.677415,\n",
              "   'run_id': 'f86498e5-8b38-49e6-82e1-71afac5d8100',\n",
              "   'output': 'The recommended dosage of Cetirizine Hydrochloride Tablets for adults, elderly patients, and children 12 years and over is 10 mg once daily as one tablet daily. If the tablets make you feel drowsy or dizzy, taking half a tablet twice a day may be better than taking one tablet once a day. For children aged 6 to 12 years, the recommended dosage is half a tablet twice daily. Children under 6 years should not take this medication. Patients with moderate renal impairment are recommended to take 5 mg once daily. It is important to consult your doctor or pharmacist for appropriate dosing if you have severe kidney problems or liver and kidney problems together. If your child suffers from kidney disease, the dose may need to be adjusted based on their needs. If you feel that the effect of the medication is too weak or too strong, consult your doctor for guidance.',\n",
              "   'reference': {'output': '\\n        For adults, elderly patients and children 12 years and over, the recommended dose is 10 mg once daily as one tablet daily.\\n        For children between 6 to 12 years old, it is half a tablet twice daily.\\n        For children below 6 years of age, it is not recommended to take this medicine.\\n        '}},\n",
              "  '3aa405ca-dfce-4fea-af4a-2b1397d6f35d': {'input': {'input': 'How long does it take to start acting?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('a86f3b2f-5072-4e63-b24e-e3c04f413b11'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 1.693089,\n",
              "   'run_id': 'e5911079-b797-44ef-a6c6-fd47777302d4',\n",
              "   'output': 'The leaflet does not specify an exact time frame for how long it takes for Cetirizine Hydrochloride Tablets to start acting. The effectiveness of the medication may vary depending on individual factors such as the type, duration, and course of your symptoms. It is recommended to consult your doctor or pharmacist for advice on the duration of treatment and when you can expect to see the effects of the medication.',\n",
              "   'reference': {'output': 'I am unable to answer this question based on the information provided.'}},\n",
              "  'ad8e6b5c-b93c-491c-863b-d7a77e72d412': {'input': {'input': 'Can it be given to children?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('136c5e0f-7c44-4bca-9e3f-f823da6f8e8d'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 1.874233,\n",
              "   'run_id': '57be9298-4a9d-4464-a95c-b10028dee903',\n",
              "   'output': \"Children under 6 years old should not be given Cetirizine Hydrochloride Tablets. It is recommended to consult with a doctor or pharmacist for children's appropriate medication options.\",\n",
              "   'reference': {'output': 'No, it should be taken by children aged less than 6 years old. Children above the age of 6 must follow the prescribed dosage - half a tablet twice daily for children between 6 and 12 years.'}},\n",
              "  '2108c3c4-c352-41c9-ba03-ca908a60790e': {'input': {'input': 'Can it be taken by pregnant women?'},\n",
              "   'feedback': [EvaluationResult(key='correctness', score=1, value='CORRECT', comment='CORRECT', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('529dee97-9bfe-4805-a3d4-268b3a8e040a'))}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
              "   'execution_time': 1.5775,\n",
              "   'run_id': '33dbdefe-17b1-4de1-b32f-3a2412526846',\n",
              "   'output': 'Cetirizine Hydrochloride Tablets should be avoided in pregnant women. If a pregnant woman accidentally uses the drug, it should not produce harmful effects on the fetus. However, it is recommended to only administer the medicine if necessary and after medical advice. Therefore, pregnant women should consult their doctor before taking this medicine.',\n",
              "   'reference': {'output': 'No, it should not be taken by pregnant women before seeking the doctors advice.'}}},\n",
              " 'aggregate_metrics': None}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After initiating the evaluation of our QnA bot using the dataset we registered, you will be able to observe several key performance metrics. These metrics include the percentage of questions answered correctly, which provides a direct measure of the bot's accuracy. You will also see the duration of the test, which gives insight into the efficiency of the bot under testing conditions. Additionally, the evaluation will report on costs and latency, offering a broader view of the bot's operational performance.\n",
        "\n",
        "This initial evaluation serves as a preliminary indication of how well your bot is performing. As the bot encounters more users and a diverse array of questions, it's crucial to continually update and adapt your baseline test dataset. This iterative process ensures that the bot remains effective and responsive to the evolving needs and contexts it will encounter in real-world applications.\n",
        "\n",
        "![Evaluation Test results](https://i.ibb.co/txtzhtD/Xnapper-2024-06-16-11-32-28.png)"
      ],
      "metadata": {
        "id": "C5PPIGVIYU8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Step 3.2:\n",
        "\n",
        "Now that you have an end to end RAG chatbot up and running, you can try to stress-test your bot by asking all kinds of questions - both relevant and irrelevant. What kind of responses does it generate? How often does it hallucinate?"
      ],
      "metadata": {
        "id": "Bj_PnIs8aouf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CgQ9dSJJa61b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}